# vim: syntax=python

rule gatk_genotypegvcfs:
    input:
        gvcf="gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.gvcf.gz"
    output:
        vcf=temp("gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.vcf")
    log:
        "gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.log"
    benchmark:
        "gatk/genotypegvcfs_benchmark.mmq{gatk_mmq}.region_{analysis_region}.tsv"
    params:
        memreq=lambda wildcards, input, output, threads, resources: str(int(resources.mem_mb/2) - 500) + "M"
    resources:
        # This likely needs to scale with number of input BAMs. ~1500MB for 5 30X BAMs
        mem_mb=4000
    shell:
        """
        gatk GenotypeGVCFs \
           --java-options '-Xmx{params.memreq} -Xms{params.memreq}' \
           --dbsnp {config[dbsnp]} \
           -R {config[ref]} \
           -V {input} \
           -O {output} >& {log}
        """


# Different from the direct joint calling GATK arg files: in this case,
# join across samples in one region.
rule make_gvcf_arg_file_per_region:
    input:
        gvcfs=expand("gatk/{sample}/hc_raw.mmq{{gatk_mmq}}.region_{{analysis_region}}.gvcf.gz",
                     sample=config['bam_map'].keys())
    output:
        listfile="gatk/arg_file_gvcfs_mmq{gatk_mmq}.region_{analysis_region}.list"
    resources:
        mem_mb=100
    localrule: True
    run:
        with open(output.listfile, 'w') as f:
            for gvcf in input.gvcfs:
                f.write("--variant " + str(gvcf) + '\n')


rule gatk_combinegvcfs:
    input:
        argfile="gatk/arg_file_gvcfs_mmq{gatk_mmq}.region_{analysis_region}.list",
        gvcfs=expand("gatk/{sample}/hc_raw.mmq{{gatk_mmq}}.region_{{analysis_region}}.gvcf.gz",
                     sample=config['bam_map'].keys())
    output:
        gvcf="gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.gvcf.gz"
    log:
        "gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.log"
    benchmark:
        "gatk/combinegvcfs_benchmark.mmq{gatk_mmq}.region_{analysis_region}.tsv"
    params:
        memreq=lambda wildcards, input, output, threads, resources: str(int(resources.mem_mb/2) - 500) + "M"
    threads: 1
    resources:
        # This likely needs to scale with number of input BAMs.  1500MB for 5 ~30X BAMs.
        mem_mb=5000
    shell:
        """
        gatk CombineGVCFs \
           --java-options '-Xmx{params.memreq} -Xms{params.memreq}' \
           --arguments_file {input.argfile} \
           -R {config[ref]} \
           -O {output} >& {log}
        """


rule gatk_scatter:
    input:
        bam=lambda wildcards: config['bam_map'][wildcards.sample]
    output:
        gvcf=temp("gatk/{sample}/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.gvcf.gz")
    log:
        "gatk/{sample}/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.log"
    benchmark:
        "gatk/{sample}/scatter_benchmark.mmq{gatk_mmq}.region_{analysis_region}.tsv"
    params:
        regionflag="-L {analysis_region}",
        mmq="{gatk_mmq}",
        # allocate half of the memory to stack, half to heap
        # it seems some JVMs allocate this memory immediately, whether used by
        # the program or not. so we subtract 1000MB (500 from stack and heap
        # each) from the total to ensure that the job isn't immediately killed
        # by the cluster scheduler.
        memreq=lambda wildcards, input, output, threads, resources: str(int(resources.mem_mb/2) - 500) + "M"
    resources:
        mem_mb=2000
    shell:
        """
        gatk HaplotypeCaller \
            --java-options '-Xmx{params.memreq} -Xms{params.memreq}' \
            --dont-use-soft-clipped-bases \
            --dbsnp {config[dbsnp]} \
            --minimum-mapping-quality {params.mmq} \
            --min-base-quality-score {config[min_base_quality_score]} \
            --emit-ref-confidence BP_RESOLUTION \
            {params.regionflag} \
            -R {config[ref]} \
            -I {input.bam} \
            -O {output.gvcf} >& {log}
        """
