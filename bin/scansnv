#!/usr/bin/env python
# vim: set syntax=python
# This is a wrapper script for executing Snakemake on the SCAN-SNV Snakefile.

import subprocess
import argparse
import os.path
import re
from sys import exit



def error(str):
    print("ERROR: " + str)
    exit(1)



# Only checks that a file path can be read.
def readable_file(path):
    try:
        with open(path, 'r') as f:
            return os.path.abspath(path)
    except IOError as err:
        error("file {0} could not be read:\n    {1}".format(path, err))



def check_refgenome(refgenome):
    """Check for FASTA index (.fai) and dictionary (.dict) files.
       Assumes refgenome has already been checked."""
    readable_file(refgenome + '.fai')
    readable_file(re.sub('.fasta$', '.dict', refgenome))



def check_dbsnp(dbsnp):
    """Check for the VCF index file (.idx).  Assumes dbsnp has already
       been checked."""
    readable_file(dbsnp + '.idx')



def check_shapeit(shapeit_panel):
    """Check all required SHAPEIT haplotype panel files. Exit if any are missing."""
    if not os.path.exists(shapeit_panel):
        print("SHAPEIT panel path does not exist: " + shapeit_panel)
    if not os.path.isdir(shapeit_panel):
        print("SHAPEIT panel path is not a directory; " + shapeit_panel)
    for i in range(1, 23):
        fname = 'genetic_map_chr{0}_combined_b37.txt'.format(i)
        readable_file(os.path.join(shapeit_panel, fname))
        for suf in [ 'hap', 'legend' ]:
            fname = "1000GP_Phase3_chr{0}.{1}.gz".format(i, suf)
            readable_file(os.path.join(shapeit_panel, fname))

    # chrX is not consistently named
    readable_file(os.path.join(shapeit_panel, "1000GP_Phase3_chrX_NONPAR.hap.gz"))
    readable_file(os.path.join(shapeit_panel, "1000GP_Phase3_chrX_NONPAR.legend.gz"))
    readable_file(os.path.join(shapeit_panel, "genetic_map_chrX_nonPAR_combined_b37.txt"))



def check_bams(sblist):
    samples = []
    bams = []
    for sample, bam in sblist:
        samples.append(sample)
        bams.append(readable_file(bam))

    return (samples, bams)



def check_regions(args):
    """Check the user specified regions or region file."""
    regions = []
    if args.regions is None and args.regions_file is None:
        regions = [ str(x) for x in range(1, 23) ]

    if not args.regions is None and not args.regions_file is None:
        error("only one of --regions or --regions-file can be supplied")

    if not args.regions is None:
        regions = args.regions.split(',')

    if not args.regions_file is None:
        with open(args.regions_file) as f:
            for line in f:
                if line.startswith("#"):
                    continue

                chrom, start, stop = line.strip().split('\t')[0:3]
                regions.append("{0}:{1}-{2}".format( chrom, int(start)+1, stop))

    chrs = []
    # retains order
    rchrs = [ r.split(":")[0] for r in regions ]
    for c in rchrs:
        if chrs.count(c) == 0:
            chrs.append(c)

    return (chrs, regions)



def make_yaml(args, samples, bams, chrs, regions):
    """Assumes reasonable checking has been performed on arguments and files.
       Returns a string containing the full YAML configuration file necessary
       for running Snakemake."""
    return '\n'.join(
        [ 'bams:' ] +
        [ '  {0}: {1}'.format(s, b) for s, b in zip(samples, bams) ] +
        [ 'sc_samples:' ] +
        [ '  - ' + s for s in args.sc_sample ] +
        [
        'bulk_sample: ' + args.bulk_sample,
        'humref: ' + args.ref,
        'dbsnp: ' + args.dbsnp,
        'shapeit_refpanel: ' + args.shapeit_panel,
        'abmodel_chunks: ' + str(args.abmodel_chunks),
        'abmodel_samples_per_chunk: ' + str(args.abmodel_samples_per_chunk),
        'abmodel_hsnp_chunksize: ' + str(args.abmodel_hsnp_chunk_size),
        'abmodel_steps: ' + str(args.abmodel_steps),
        'fdr: ' + str(args.target_fdr),
        'min_sc_alt: ' + str(args.min_sc_alt),
        'min_sc_dp: ' + str(args.min_sc_dp),
        'min_bulk_dp: ' + str(args.min_bulk_dp),
        'spikein_replicates: ' + str(args.hsnp_spikein_replicates),
        'hsnp_spikein_size: ' + str(args.hsnp_spikein_replicate_size),
        'hsnp_spikein_nsamples: ' + str(args.hsnp_spikein_replicates * args.hsnp_spikein_replicate_size),
        'gatk_chunks: ' + str(len(regions)),
        'gatk_regions: '
        ] +
        [ '  - ' + r for r in regions ] +
        [
        'chrs: '
        ] +
        [ '  - ' + c for c in chrs ] +
        [ 
        'scripts: ' + args.scripts
        ] +
        [ '' ]
    )



ap = argparse.ArgumentParser(description='Somatic SNV genotyper for whole genome amplified single cell sequencing experiments.',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

ap.add_argument('--cluster', default=None, type=str, metavar='ARGS',
    help="Pass ARGS to Snakemake's --cluster parameter.  Do not use --snakemake-args to access --cluster.  Memory requirements for each job can be accessed via {resources.mem} and any instance of '%%logdir' in ARGS will be replaced by --output-dir/cluster-logs.")
ap.add_argument('--drmaa', default=None, type=str, metavar='ARGS',
    help="Pass ARGS to Snakemake's --drmaa parameter.  Do not use --snakemake-args to access --drmaa.  Memory requirements for each job can be accessed via {resources.mem} and any instance of '%%logdir' in ARGS will be replaced by --output-dir/cluster-logs.")

ap.add_argument('--joblimit', default=1, metavar='INT',
    help='Allow at most INT jobs to execute at any given time.  For multicore machines or clusters, this can greatly decrease runtime.')
ap.add_argument('--memlimit', default=None, metavar='INT', type=int,
    help="Total available memory in MB.  If unspecified, memory is treated as unlimited.")
ap.add_argument('--resume', action='store_true', default=False,
    help='Restart a previously running analysis.  --output-dir should point to a directory created by scansnv.  IMPORTANT: any new parameters specified in a resume run WILL BE IGNORED unless --overwrite is also given.')
ap.add_argument('--overwrite', default=False, action='store_true',
    help='Overwrite a previously-generated Snakemake configuration file. The old file will be renamed to {--output-dir/config.yaml.old}, but this could cause loss of information.')
ap.add_argument('--scripts', metavar='PATH',
    default='/opt/anaconda1anaconda2anaconda3/lib/scansnv',
    help='Path to SCAN-SNV script files.  Usually points to an installed set of files.')


# required arguments
req = ap.add_argument_group("Required arguments")
req.add_argument('--ref', type=readable_file, metavar='PATH', required=True,
    help='Path to reference genome FASTA file.  As required by GATK, two additional files must be present: an index (.fai) and a dictionary (.dict).')
req.add_argument('--dbsnp', type=readable_file, metavar='PATH', required=True,
    help='Path to an indexed dbSNP VCF.')
req.add_argument('--shapeit-panel', metavar='DIR', required=True,
    help='Path to the 1000 genomes project phase 3 SHAPEIT panel.  At this time, other phasing panels are not supported.')
req.add_argument('--output-dir', metavar='DIR', required=True,
    help='Write all output files to DIR.')



infiles = ap.add_argument_group('Input sequencing data',
    'At least two BAM files must be specified via --bam arguments.  Exactly one sample must be identified as bulk and at least one as single cell.  Samples not identified as either bulk or single cell will be used for GATK joint calling.  This can be useful for, e.g., including related single cells for building a truth set.')
infiles.add_argument('--bam',  nargs=2, action='append', required=True, metavar=('SAMPLE_ID', 'BAM_FILE'),
    help='BAM_FILE must be indexed and may contain reads from only one sample.  The SAMPLE_ID *must* match the SM: tag in the corresponding BAM_FILE.  May be specified several times.')
infiles.add_argument('--bulk-sample', metavar='SAMPLE_ID', required=True,
    help='Non-single cell (bulk) sample for removing germline or clonal SNVs.  Only one sample may be designated as the bulk sample.')
infiles.add_argument('--sc-sample', metavar='SAMPLE_ID', action='append', required=True,
    help='Mark SAMPLE_ID as a single cell to be genotyped.  May be specified multiple times.')



gatk = ap.add_argument_group('Genotyping intervals',
    'These parameters allow the user to specify which portions of the genome should be genotyped.  By default, all autosomal regions will be analyzed.  Regions MUST be specified in the same order as the reference genome and should not overlap!!  The maximum target region is chrs 1-22 and X, due to the SHAPEIT reference panel.  Non-pseudoautosomal regions (PARs) on chrX may also be analyzed, but male samples may fail due to lack of hSNPs.  Initial GATK calling will be performed on each region in parallel if possible, which can greatly decrease runtime.')
gatk.add_argument('--regions', metavar="STRING", default=None,
    help='A comma separated list of regions in GATK format: chr:start-stop, e.g. 22:30000001-31000000,22:31000001-32000000.  Cannot be specified in addition to --regions-file.')
gatk.add_argument('--regions-file', metavar='PATH', default=None,
    help='A BED file containing regions to be analyzed.  Cannot be specified in addition to --regions.')
# NOT YET IMPLEMENTED
# Convenience function to autogenerate the region list
#gatk.add_argument('--gatk-window-size', default=10000000, type=int, metavar='INT',
#    help='Split the genome into windows no larger than INT basepairs.  Run GATK on each window in parallel.  On a system with many cores or a cluster, decreasing the window size will speed up the initial GATK step.  Because windows are interrupted at chromosome boundaries, one window per chromosome may be much smaller than INT.  REQUIRES BEDTOOLS.  Cannot be specified in conjunction with --regions.')



caller = ap.add_argument_group("Somatic SNV calling parameters. A minimum requirement of 2 reads supporting a putative mutation is probably good practice at most sequencing depths.  However, the minimum total depth for single cell and bulk may need to be altered.  The defaults of 6 and 11, respectively, were successful on single cells with >25x and bulk with >30x mean coverage.")
caller.add_argument('--target-fdr', type=float, default=0.1, metavar='FLOAT',
    help='Desired false discovery rate (FDR).  This is not formal FDR control via, e.g., q-values.  In general, lower values will increase specificity at the cost of sensitivity.')
caller.add_argument('--min-sc-alt', type=int, default=2, metavar='INT',
    help='Reject somatic SNVs with fewer than INT reads carrying the mutation in single cells.')
caller.add_argument('--min-sc-dp', type=int, default=6, metavar='INT',
    help='Reject somatic SNVs covered by fewer than INT reads in single cells.')
caller.add_argument('--min-bulk-dp', type=int, default=11, metavar='INT',
    help='Reject somatic SNVs covered by fewer than INT reads in bulk.')


abmodel = ap.add_argument_group("AB model fitting",
    "These parameters control the exhaustive parameter search used to fit an AB correlation function for each chromosome.  This is by far the most time consuming step of the calling process.  None of these parameters are used for subsequent AB inference.")
abmodel.add_argument('--abmodel-chunks', type=int, default=20, metavar='INT',
    help='Split each AB model sampling stage into INT jobs per chromosome.  When multiple threads or a cluster are available, this will drastically shorten total runtime.')
abmodel.add_argument('--abmodel-samples-per-chunk', type=int, default=1000, metavar='INT',
    help='Sample the AB model log-likelihood function INT times for each chunk.  The total number of samples for each chromosome will be (--abmodel-chunks) * (--abmodel-samples-per-chunk).')
abmodel.add_argument('--abmodel-hsnp-chunk-size', type=int, default=100, metavar='INT',
    help='Approximate the AB model likelihood function for each chromosome by breaking hSNPs into non-overlapping chunks of size INT.  Larger values significantly increase runtime, but may be necessary for organisms with high SNP density (e.g., >1 hSNP per kilobase on average).')
abmodel.add_argument('--abmodel-steps', type=int, default=4, metavar='INT',
    help='Refine the parameter space for random sampling INT times.  After the first log-likelihood sampling has completed, a new parameter space is defined so as to contain the 50 points with highest log likelihood.')



spikein = ap.add_argument_group("hSNP spike-ins",
    'hSNP spike ins provide a way to estimate sensitivity and the effects of various filters.  hSNP spikeins are also used to train models for excess indel and read clipping, so at least a few thousand spikeins should be used.  However, hSNP spike-ins must be performed in many small batches for two reasons: (1) spike-ins hSNPs are not included in the list of hSNPs used to infer AB and (2) spike-ins are treated as sSNVs in the parameter tuning process which compares sSNV vs. hSNP VAF distributions.  See the SCAN-SNV paper for details.')
spikein.add_argument('--hsnp-spikein-replicates', type=int, default=100, metavar='INT',
    help='Perform INT separate hSNP spike in experiments, each with (--hsnp-spikein-replicate-size) spiked-in hSNPs.')
spikein.add_argument('--hsnp-spikein-replicate-size', type=int, default=40, metavar='INT',
    help='Number of hSNPs to spike-in for each replicate.')


snakemake = ap.add_argument_group("Snakemake parameters")
snakemake.add_argument('--snakemake-args', default='', type=str, metavar='STRING',
    help='STRING is a set of command line arguments to be passed to Snakemake.  Note that a leading space may be necessary, e.g., --snakemake-args " --drmaa \' -p myqueue -t 12:00:00 --mem={resources.mem}\'".')
snakemake.add_argument('--snakefile', metavar='PATH', type=readable_file,
    default='/opt/anaconda1anaconda2anaconda3/lib/scansnv/Snakefile',
    help='Path to the SCAN-SNV Snakefile.  Unlikely to be necessary for standard use.')
snakemake.add_argument('--configfile', metavar='PATH', default=None, type=readable_file,
    help='Path to the Snakemake configuration file.  This file is autogenerated by this script and the user should rarely need to specify their own config file.')
snakemake.add_argument('--clusterfile', metavar='PATH', type=readable_file,
    default='/opt/anaconda1anaconda2anaconda3/lib/scansnv/cluster.yaml',
    help='Override the installed cluster configuration file.  This will disable the ability to specify memory requirements to --cluster and --drmaa via {resources.mem}.')

args = ap.parse_args()


os.makedirs(args.output_dir, exist_ok=True)

# Some input files must be paired with auxiliary files like indexes. Ensure
# these files exist before starting the pipeline to reduce possible headaches.
check_refgenome(args.ref)

check_dbsnp(args.dbsnp)

args.shapeit_panel = os.path.abspath(args.shapeit_panel)
check_shapeit(args.shapeit_panel)

(samples, bams) = check_bams(args.bam)
for sc in args.sc_sample:
    if not sc in samples:
        error("single cell sample {0} is not associated with a BAM file.".format(sc))
if not args.bulk_sample in samples:
    error("bulk sample {0} is not associated with a BAM file.".format(args.bulk_sample))

(chrs, regions) = check_regions(args)

if args.configfile is not None:
    configfile = args.configfile
else:
    configfile = os.path.abspath(os.path.join(args.output_dir, "config.yaml"))
    if os.path.exists(configfile):
        if args.resume and not args.overwrite:
            print("WARNING: new parameters are IGNORED because --overwrite was not given.")
        if not args.overwrite and not args.resume:
            error("configuration file {0} exists already. Please use --resume or --overwrite to proceed.".format(configfile))
        if args.overwrite:
            os.rename(configfile, configfile + ".old")

    with open(configfile, 'w') as f:
        f.write(make_yaml(args, samples, bams, chrs, regions))




snakemake_command = [
    "snakemake",
    "--snakefile",  args.snakefile,
    "--configfile", configfile,
    "--jobs", args.joblimit,
    "--latency-wait", "60",
    ]

if args.memlimit:
    snakemake_command += [ "--resources",  "mem=" + str(args.memlimit) ]

if args.resume:
    snakemake_command.append("--rerun-incomplete")

if args.cluster is not None or args.drmaa is not None:
    if args.cluster is not None and args.drmaa is not None:
        error('only one of --cluster and --drmaa can be specified at once')

    snakemake_command += [ "--cluster-config", args.clusterfile ]
    logdir = os.path.join(os.path.abspath(args.output_dir), 'cluster-logs')

    if args.cluster is not None:
        if '%logdir' in args.cluster:
            os.makedirs(logdir, exist_ok=True)
        snakemake_command += [ '--cluster',
            re.sub('%logdir', logdir, args.cluster) ]
    else:
        if '%logdir' in args.drmaa:
            os.makedirs(logdir, exist_ok=True)
        snakemake_command += [ '--drmaa',
            re.sub('%logdir', logdir, args.drmaa) ]


if args.snakemake_args:
    if args.snakemake_args[0] == ' ':
        args.snakemake_args = args.snakemake_args[1:]
    snakemake_command += args.snakemake_args.split(' ')


# So that we can wait for Snakemake to exit even when ctrl+C is given
try:
    print(' '.join(snakemake_command))
    sp = subprocess.Popen(snakemake_command, cwd=args.output_dir)
    sp.wait()
except KeyboardInterrupt:
    print("Waiting for Snakemake to respond to SIGINT...")
    sp.wait()
